{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####hourly data\n",
    "ae_index = pd.read_excel('3 AE_index_20.xls')\n",
    "ap_index = pd.read_excel('3 ap_index_20.xls')\n",
    "dst_index = pd.read_excel('3 DST_index_20.xls')\n",
    "kp_index = pd.read_excel('3 kp_index_20.xls')\n",
    "\n",
    "####daily data\n",
    "f_value = pd.read_excel('3 f 10.7cm-20.xls')\n",
    "ssn = pd.read_excel('3 SSN-20.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fof2 = pd.read_excel('3 Can_foF2Data_20.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19751227</th>\n",
       "      <td>361</td>\n",
       "      <td>166</td>\n",
       "      <td>183</td>\n",
       "      <td>80</td>\n",
       "      <td>197</td>\n",
       "      <td>276</td>\n",
       "      <td>411</td>\n",
       "      <td>410</td>\n",
       "      <td>647</td>\n",
       "      <td>327</td>\n",
       "      <td>...</td>\n",
       "      <td>292</td>\n",
       "      <td>1112</td>\n",
       "      <td>1179</td>\n",
       "      <td>813</td>\n",
       "      <td>677</td>\n",
       "      <td>720</td>\n",
       "      <td>671</td>\n",
       "      <td>473</td>\n",
       "      <td>435</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19751228</th>\n",
       "      <td>362</td>\n",
       "      <td>544</td>\n",
       "      <td>322</td>\n",
       "      <td>141</td>\n",
       "      <td>172</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>135</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>92</td>\n",
       "      <td>333</td>\n",
       "      <td>138</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>371</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19751229</th>\n",
       "      <td>363</td>\n",
       "      <td>275</td>\n",
       "      <td>198</td>\n",
       "      <td>82</td>\n",
       "      <td>142</td>\n",
       "      <td>176</td>\n",
       "      <td>361</td>\n",
       "      <td>360</td>\n",
       "      <td>299</td>\n",
       "      <td>385</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>92</td>\n",
       "      <td>338</td>\n",
       "      <td>161</td>\n",
       "      <td>345</td>\n",
       "      <td>525</td>\n",
       "      <td>172</td>\n",
       "      <td>202</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19751230</th>\n",
       "      <td>364</td>\n",
       "      <td>169</td>\n",
       "      <td>246</td>\n",
       "      <td>174</td>\n",
       "      <td>224</td>\n",
       "      <td>305</td>\n",
       "      <td>223</td>\n",
       "      <td>112</td>\n",
       "      <td>125</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>108</td>\n",
       "      <td>71</td>\n",
       "      <td>128</td>\n",
       "      <td>239</td>\n",
       "      <td>107</td>\n",
       "      <td>83</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19751231</th>\n",
       "      <td>365</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>113</td>\n",
       "      <td>162</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>78</td>\n",
       "      <td>103</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DOY    0    1    2    3    4    5    6    7    8 ...    14    15  \\\n",
       "19751227  361  166  183   80  197  276  411  410  647  327 ...   292  1112   \n",
       "19751228  362  544  322  141  172  220  227  135   88   89 ...    47    51   \n",
       "19751229  363  275  198   82  142  176  361  360  299  385 ...   119    92   \n",
       "19751230  364  169  246  174  224  305  223  112  125  177 ...   132    73   \n",
       "19751231  365   42   51  113  162   37   32   51  104   36 ...    99    78   \n",
       "\n",
       "            16   17   18   19   20   21   22   23  \n",
       "19751227  1179  813  677  720  671  473  435  341  \n",
       "19751228    92  333  138  111   95  101  371  157  \n",
       "19751229   338  161  345  525  172  202   85   85  \n",
       "19751230    85  108   71  128  239  107   83  124  \n",
       "19751231   103   53   54   47   37   41   63   42  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_index.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_index = ae_index.drop('DOY', axis = 1)\n",
    "ap_index = ap_index.drop('DOY', axis = 1)\n",
    "dst_index = dst_index.drop('DOY', axis = 1)\n",
    "kp_index = kp_index.drop('DOY', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fof2 = fof2.drop('DOY', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "mean_imputer = imp.fit(f_value)\n",
    "names = f_value.columns.values\n",
    "f_value = pd.DataFrame(mean_imputer.transform(f_value))\n",
    "f_value.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_indices = []\n",
    "for i in ae_index.index.values:\n",
    "    for j in range(24):\n",
    "        ae_indices.append(str(i)+'_'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_index_1 = pd.DataFrame([ae_indices,ae_index.values.flatten().tolist()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_index_1.columns = ['Time', 'ae_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_indices = []\n",
    "for i in ap_index.index.values:\n",
    "    for j in range(24):\n",
    "        ap_indices.append(str(i)+'_'+str(j))\n",
    "        \n",
    "\n",
    "ap_index_1 = pd.DataFrame([ap_indices,ap_index.values.flatten().tolist()]).T\n",
    "\n",
    "ap_index_1.columns = ['Time', 'ap_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_indices = []\n",
    "for i in dst_index.index.values:\n",
    "    for j in range(24):\n",
    "        dst_indices.append(str(i)+'_'+str(j))\n",
    "        \n",
    "\n",
    "dst_index_1 = pd.DataFrame([dst_indices,dst_index.values.flatten().tolist()]).T\n",
    "\n",
    "dst_index_1.columns = ['Time', 'dst_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_indices = []\n",
    "for i in kp_index.index.values:\n",
    "    for j in range(24):\n",
    "        kp_indices.append(str(i)+'_'+str(j))\n",
    "        \n",
    "\n",
    "kp_index_1 = pd.DataFrame([kp_indices,kp_index.values.flatten().tolist()]).T\n",
    "\n",
    "kp_index_1.columns = ['Time', 'kp_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_indices = []\n",
    "for i in f_value.index.values:\n",
    "    for j in range(24):\n",
    "        f_indices.append((str(int(f_value['YEAR'][i]))+'_'+str(j), f_value['f10.7_index'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value_1 = pd.DataFrame(f_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value_1.columns = ['Time', 'f_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn_indices = []\n",
    "for i in ssn.index.values:\n",
    "    for j in range(24):\n",
    "        ssn_indices.append((str(ssn['year'][i])+'_'+str(j), ssn['R (Sunspot No.)'][i]))\n",
    "        \n",
    "ssn_1 = pd.DataFrame(ssn_indices)\n",
    "\n",
    "ssn_1.columns = ['Time', 'ssn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fof2_indices = []\n",
    "for i in fof2.index.values:\n",
    "    for j in range(24):\n",
    "        fof2_indices.append(str(fof2['C-20'][i])+'_'+str(j))\n",
    "        \n",
    "\n",
    "fof2_1 = pd.DataFrame([fof2_indices,fof2.drop('C-20', axis = 1).values.flatten().tolist()]).T\n",
    "\n",
    "fof2_1.columns = ['Time', 'fof2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Tables = ae_index_1, ap_index_1, kp_index_1, dst_index_1, f_value_1, ssn_1, fof2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(ae_index_1, ap_index_1, how = 'inner', on = 'Time')\n",
    "data = pd.merge(data, dst_index_1, how = 'inner', on = 'Time')\n",
    "data = pd.merge(data, kp_index_1, how = 'inner', on = 'Time')\n",
    "data = pd.merge(data, ssn_1, how = 'inner', on = 'Time')\n",
    "data = pd.merge(data, f_value_1, how = 'inner', on = 'Time')\n",
    "data = pd.merge(data, fof2_1, how = 'inner', on = 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ae_value</th>\n",
       "      <th>ap_value</th>\n",
       "      <th>dst_value</th>\n",
       "      <th>kp_value</th>\n",
       "      <th>ssn</th>\n",
       "      <th>f_value</th>\n",
       "      <th>fof2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19641001_0</td>\n",
       "      <td>339</td>\n",
       "      <td>22</td>\n",
       "      <td>-19</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19641001_1</td>\n",
       "      <td>277</td>\n",
       "      <td>22</td>\n",
       "      <td>-14</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19641001_2</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>-12</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19641001_3</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>-12</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19641001_4</td>\n",
       "      <td>285</td>\n",
       "      <td>18</td>\n",
       "      <td>-13</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19641001_5</td>\n",
       "      <td>165</td>\n",
       "      <td>18</td>\n",
       "      <td>-13</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19641001_6</td>\n",
       "      <td>113</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19641001_7</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>-11</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19641001_8</td>\n",
       "      <td>265</td>\n",
       "      <td>9</td>\n",
       "      <td>-8</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19641001_9</td>\n",
       "      <td>246</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19641001_10</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19641001_11</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>-10</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19641001_12</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>-7</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19641001_13</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19641001_14</td>\n",
       "      <td>238</td>\n",
       "      <td>6</td>\n",
       "      <td>-10</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19641001_15</td>\n",
       "      <td>138</td>\n",
       "      <td>9</td>\n",
       "      <td>-13</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19641001_16</td>\n",
       "      <td>220</td>\n",
       "      <td>9</td>\n",
       "      <td>-13</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19641001_17</td>\n",
       "      <td>172</td>\n",
       "      <td>9</td>\n",
       "      <td>-9</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19641001_18</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19641001_19</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19641001_20</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>-10</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19641001_21</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19641001_22</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>-10</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19641001_23</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>-13</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19641002_0</td>\n",
       "      <td>173</td>\n",
       "      <td>12</td>\n",
       "      <td>-12</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19641002_1</td>\n",
       "      <td>232</td>\n",
       "      <td>12</td>\n",
       "      <td>-10</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19641002_2</td>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "      <td>-8</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19641002_3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19641002_4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19641002_5</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98586</th>\n",
       "      <td>19751230_18</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>-13</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98587</th>\n",
       "      <td>19751230_19</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>-15</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98588</th>\n",
       "      <td>19751230_20</td>\n",
       "      <td>239</td>\n",
       "      <td>12</td>\n",
       "      <td>-15</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98589</th>\n",
       "      <td>19751230_21</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>-11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98590</th>\n",
       "      <td>19751230_22</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>-12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98591</th>\n",
       "      <td>19751230_23</td>\n",
       "      <td>124</td>\n",
       "      <td>7</td>\n",
       "      <td>-15</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98592</th>\n",
       "      <td>19751231_0</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>-16</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98593</th>\n",
       "      <td>19751231_1</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>-13</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98594</th>\n",
       "      <td>19751231_2</td>\n",
       "      <td>113</td>\n",
       "      <td>15</td>\n",
       "      <td>-12</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98595</th>\n",
       "      <td>19751231_3</td>\n",
       "      <td>162</td>\n",
       "      <td>12</td>\n",
       "      <td>-10</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98596</th>\n",
       "      <td>19751231_4</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>-9</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98597</th>\n",
       "      <td>19751231_5</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>-8</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98598</th>\n",
       "      <td>19751231_6</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98599</th>\n",
       "      <td>19751231_7</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>-7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98600</th>\n",
       "      <td>19751231_8</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>-7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98601</th>\n",
       "      <td>19751231_9</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98602</th>\n",
       "      <td>19751231_10</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98603</th>\n",
       "      <td>19751231_11</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98604</th>\n",
       "      <td>19751231_12</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>-6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98605</th>\n",
       "      <td>19751231_13</td>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98606</th>\n",
       "      <td>19751231_14</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98607</th>\n",
       "      <td>19751231_15</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98608</th>\n",
       "      <td>19751231_16</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98609</th>\n",
       "      <td>19751231_17</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98610</th>\n",
       "      <td>19751231_18</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98611</th>\n",
       "      <td>19751231_19</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>-5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98612</th>\n",
       "      <td>19751231_20</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98613</th>\n",
       "      <td>19751231_21</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>-2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98614</th>\n",
       "      <td>19751231_22</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "      <td>-2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98615</th>\n",
       "      <td>19751231_23</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>-2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98616 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time ae_value ap_value dst_value kp_value  ssn  f_value fof2\n",
       "0       19641001_0      339       22       -19       37   25     72.0  4.8\n",
       "1       19641001_1      277       22       -14       37   25     72.0  5.2\n",
       "2       19641001_2       57       22       -12       37   25     72.0  5.3\n",
       "3       19641001_3       74       18       -12       33   25     72.0  5.5\n",
       "4       19641001_4      285       18       -13       33   25     72.0  5.5\n",
       "5       19641001_5      165       18       -13       33   25     72.0  4.5\n",
       "6       19641001_6      113        9       -12       23   25     72.0    5\n",
       "7       19641001_7      143        9       -11       23   25     72.0  4.9\n",
       "8       19641001_8      265        9        -8       23   25     72.0  4.4\n",
       "9       19641001_9      246        6        -8       17   25     72.0  4.3\n",
       "10     19641001_10       92        6        -8       17   25     72.0  4.1\n",
       "11     19641001_11      131        6       -10       17   25     72.0    4\n",
       "12     19641001_12       96        6        -7       17   25     72.0  3.7\n",
       "13     19641001_13       95        6        -8       17   25     72.0  3.4\n",
       "14     19641001_14      238        6       -10       17   25     72.0  3.1\n",
       "15     19641001_15      138        9       -13       23   25     72.0  2.9\n",
       "16     19641001_16      220        9       -13       23   25     72.0  2.8\n",
       "17     19641001_17      172        9        -9       23   25     72.0  2.9\n",
       "18     19641001_18       70        2        -8        3   25     72.0  2.4\n",
       "19     19641001_19       52        2        -8        3   25     72.0  2.5\n",
       "20     19641001_20       30        2       -10        3   25     72.0  3.4\n",
       "21     19641001_21       27        3        -9        7   25     72.0  4.5\n",
       "22     19641001_22       29        3       -10        7   25     72.0  5.2\n",
       "23     19641001_23       69        3       -13        7   25     72.0  5.2\n",
       "24      19641002_0      173       12       -12       27   18     71.6  5.8\n",
       "25      19641002_1      232       12       -10       27   18     71.6  5.9\n",
       "26      19641002_2       79       12        -8       27   18     71.6  NaN\n",
       "27      19641002_3       27        3        -5        7   18     71.6  NaN\n",
       "28      19641002_4       19        3        -3        7   18     71.6  5.6\n",
       "29      19641002_5       18        3        -2        7   18     71.6  5.5\n",
       "...            ...      ...      ...       ...      ...  ...      ...  ...\n",
       "98586  19751230_18       71       12       -13       27    0     71.9  2.7\n",
       "98587  19751230_19      128       12       -15       27    0     71.9  3.1\n",
       "98588  19751230_20      239       12       -15       27    0     71.9    4\n",
       "98589  19751230_21      107        7       -11       20    0     71.9  4.6\n",
       "98590  19751230_22       83        7       -12       20    0     71.9  4.1\n",
       "98591  19751230_23      124        7       -15       20    0     71.9  4.4\n",
       "98592   19751231_0       42       15       -16       30    0     72.1  4.5\n",
       "98593   19751231_1       51       15       -13       30    0     72.1  5.1\n",
       "98594   19751231_2      113       15       -12       30    0     72.1  5.5\n",
       "98595   19751231_3      162       12       -10       27    0     72.1  5.1\n",
       "98596   19751231_4       37       12        -9       27    0     72.1  5.1\n",
       "98597   19751231_5       32       12        -8       27    0     72.1  5.1\n",
       "98598   19751231_6       51        4        -9       10    0     72.1    5\n",
       "98599   19751231_7      104        4        -7       10    0     72.1  5.6\n",
       "98600   19751231_8       36        4        -7       10    0     72.1  5.8\n",
       "98601   19751231_9       33        4        -6       10    0     72.1  NaN\n",
       "98602  19751231_10       43        4        -6       10    0     72.1  5.5\n",
       "98603  19751231_11      113        4        -6       10    0     72.1  4.6\n",
       "98604  19751231_12      126        3        -6        7    0     72.1  4.6\n",
       "98605  19751231_13      134        3        -9        7    0     72.1  4.5\n",
       "98606  19751231_14       99        3        -9        7    0     72.1  4.6\n",
       "98607  19751231_15       78        4        -5       10    0     72.1  4.2\n",
       "98608  19751231_16      103        4        -2       10    0     72.1  3.6\n",
       "98609  19751231_17       53        4        -4       10    0     72.1  3.5\n",
       "98610  19751231_18       54        6        -3       17    0     72.1  3.4\n",
       "98611  19751231_19       47        6        -5       17    0     72.1  3.8\n",
       "98612  19751231_20       37        6        -3       17    0     72.1  4.8\n",
       "98613  19751231_21       41        7        -2       20    0     72.1  5.2\n",
       "98614  19751231_22       63        7        -2       20    0     72.1  4.7\n",
       "98615  19751231_23       42        7        -2       20    0     72.1  4.8\n",
       "\n",
       "[98616 rows x 8 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[data['fof2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = data[data['fof2'].isnull()==False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data.index = range(t_data.shape[0])\n",
    "test_data.index = range(test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91948, 8), (6668, 8))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data1 = pd.DataFrame(scale(t_data.drop(['Time','fof2'], axis = 1)))\n",
    "t_data1['fof2'] = t_data['fof2']\n",
    "t_data = t_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(t_data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73558, 7)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.index = range(train_data.shape[0])\n",
    "val_data.index = range(val_data.shape[0])\n",
    "test_data.index = range(test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>fof2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916106</td>\n",
       "      <td>0.795916</td>\n",
       "      <td>-1.619500</td>\n",
       "      <td>1.314619</td>\n",
       "      <td>1.021167</td>\n",
       "      <td>0.393846</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.837418</td>\n",
       "      <td>-0.602453</td>\n",
       "      <td>0.436806</td>\n",
       "      <td>-1.312253</td>\n",
       "      <td>-1.204221</td>\n",
       "      <td>-1.264410</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.863205</td>\n",
       "      <td>-0.546518</td>\n",
       "      <td>-0.101750</td>\n",
       "      <td>-1.028267</td>\n",
       "      <td>0.779277</td>\n",
       "      <td>0.686987</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127020</td>\n",
       "      <td>-0.322779</td>\n",
       "      <td>-0.199669</td>\n",
       "      <td>-0.105312</td>\n",
       "      <td>-0.607559</td>\n",
       "      <td>-0.419475</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.703325</td>\n",
       "      <td>-0.490583</td>\n",
       "      <td>0.877443</td>\n",
       "      <td>-0.815277</td>\n",
       "      <td>-1.091339</td>\n",
       "      <td>-1.051740</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5 fof2\n",
       "0  0.916106  0.795916 -1.619500  1.314619  1.021167  0.393846  8.4\n",
       "1 -0.837418 -0.602453  0.436806 -1.312253 -1.204221 -1.264410  5.1\n",
       "2 -0.863205 -0.546518 -0.101750 -1.028267  0.779277  0.686987  5.3\n",
       "3  0.127020 -0.322779 -0.199669 -0.105312 -0.607559 -0.419475    7\n",
       "4 -0.703325 -0.490583  0.877443 -0.815277 -1.091339 -1.051740  3.5"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data.drop(['fof2'],axis = 1)\n",
    "train_Y = train_data['fof2']\n",
    "val_X = val_data.drop(['fof2'],axis = 1)\n",
    "val_Y = val_data['fof2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 16\n",
    "n_hidden_3 = 8\n",
    "n_epochs = 50\n",
    "batch_size = 128\n",
    "n_batch = int(train_data.shape[0]/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape = [None, 6], dtype = tf.float32, name = 'input_X')\n",
    "Y = tf.placeholder(shape = [None], dtype = tf.float32, name = 'output_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_variable('W1', shape = [6, n_hidden_1],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "W2 = tf.get_variable('W2', shape = [n_hidden_1, n_hidden_2],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "W3 = tf.get_variable('W3', shape = [n_hidden_2, n_hidden_3],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "W4 = tf.get_variable('W4', shape = [n_hidden_3, 1],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "B1 = tf.get_variable(name='B1', shape=[n_hidden_1], initializer=tf.zeros_initializer())\n",
    "B2 = tf.get_variable(name='B2', shape=[n_hidden_2], initializer=tf.zeros_initializer())\n",
    "B3 = tf.get_variable(name='B3', shape=[n_hidden_3], initializer=tf.zeros_initializer())\n",
    "B4 = tf.get_variable(name='B4', shape=[1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    layer1 = tf.nn.tanh(tf.add(tf.matmul(X, W1), B1))\n",
    "    layer2 = tf.nn.tanh(tf.add(tf.matmul(layer1,W2), B2))\n",
    "    layer3 = (tf.add(tf.matmul(layer2,W3), B3))\n",
    "    layer4 = tf.add(tf.matmul(layer3, W4), B4)\n",
    "    return layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(out - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = tf.train.AdamOptimizer(0.1)\n",
    "train_step = op.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 val_loss = 4.179405 train_loss = 2.9738934\n",
      "[[6.260898 ]\n",
      " [6.096891 ]\n",
      " [6.140788 ]\n",
      " [6.2139845]\n",
      " [6.096674 ]\n",
      " [6.2380075]\n",
      " [6.0870433]\n",
      " [6.0963497]\n",
      " [6.077402 ]\n",
      " [6.0734386]]\n",
      "Epoch = 2 val_loss = 4.1996603 train_loss = 2.963067\n",
      "[[6.046649 ]\n",
      " [6.303482 ]\n",
      " [6.2622185]\n",
      " [6.3102984]\n",
      " [6.31214  ]\n",
      " [6.079768 ]\n",
      " [6.2954273]\n",
      " [6.275175 ]\n",
      " [6.2662687]\n",
      " [6.2608576]]\n",
      "Epoch = 3 val_loss = 4.1476083 train_loss = 3.0085657\n",
      "[[5.958871 ]\n",
      " [6.1534886]\n",
      " [6.0299253]\n",
      " [6.142153 ]\n",
      " [6.1540833]\n",
      " [5.9685082]\n",
      " [6.0634623]\n",
      " [5.98457  ]\n",
      " [5.9858437]\n",
      " [5.965081 ]]\n",
      "Epoch = 4 val_loss = 4.160518 train_loss = 2.9661245\n",
      "[[6.0863805]\n",
      " [6.150638 ]\n",
      " [6.149506 ]\n",
      " [6.152346 ]\n",
      " [6.15139  ]\n",
      " [6.1090555]\n",
      " [6.1546965]\n",
      " [6.216746 ]\n",
      " [6.209978 ]\n",
      " [6.2239323]]\n",
      "Epoch = 5 val_loss = 4.1446996 train_loss = 3.0995545\n",
      "[[5.815869 ]\n",
      " [6.0515447]\n",
      " [5.788616 ]\n",
      " [6.0506287]\n",
      " [6.051506 ]\n",
      " [5.840479 ]\n",
      " [5.88103  ]\n",
      " [5.790166 ]\n",
      " [5.7931046]\n",
      " [5.881872 ]]\n",
      "Epoch = 6 val_loss = 4.132255 train_loss = 3.0465739\n",
      "[[5.856576 ]\n",
      " [5.9552   ]\n",
      " [5.9190016]\n",
      " [5.9530253]\n",
      " [5.953368 ]\n",
      " [5.830906 ]\n",
      " [6.1110764]\n",
      " [6.0045404]\n",
      " [5.982815 ]\n",
      " [6.145282 ]]\n",
      "Epoch = 7 val_loss = 4.1303506 train_loss = 3.0418472\n",
      "[[6.0398555]\n",
      " [5.9026275]\n",
      " [5.9620557]\n",
      " [5.9894032]\n",
      " [5.9333706]\n",
      " [6.037253 ]\n",
      " [5.9414606]\n",
      " [5.961135 ]\n",
      " [5.9610763]\n",
      " [5.9439964]]\n",
      "Epoch = 8 val_loss = 4.129875 train_loss = 3.0675673\n",
      "[[5.890073 ]\n",
      " [5.9181433]\n",
      " [5.9446692]\n",
      " [5.876877 ]\n",
      " [5.919751 ]\n",
      " [5.908486 ]\n",
      " [5.9356704]\n",
      " [5.9536695]\n",
      " [5.953693 ]\n",
      " [5.9444604]]\n",
      "Epoch = 9 val_loss = 4.133836 train_loss = 3.0132046\n",
      "[[6.0269523]\n",
      " [5.9685307]\n",
      " [6.0865684]\n",
      " [5.9719853]\n",
      " [5.945574 ]\n",
      " [6.0180535]\n",
      " [6.019207 ]\n",
      " [6.063998 ]\n",
      " [6.062242 ]\n",
      " [6.053014 ]]\n",
      "Epoch = 10 val_loss = 4.1424246 train_loss = 3.1024158\n",
      "[[5.9024076]\n",
      " [5.802197 ]\n",
      " [6.013776 ]\n",
      " [5.790042 ]\n",
      " [5.802073 ]\n",
      " [5.8711214]\n",
      " [5.8330793]\n",
      " [5.9923177]\n",
      " [5.9443974]\n",
      " [5.876894 ]]\n",
      "Epoch = 11 val_loss = 4.1325307 train_loss = 3.0359042\n",
      "[[6.067576]\n",
      " [5.944534]\n",
      " [5.942572]\n",
      " [6.052357]\n",
      " [5.944534]\n",
      " [6.067576]\n",
      " [5.944534]\n",
      " [5.944534]\n",
      " [5.944534]\n",
      " [5.944534]]\n",
      "Epoch = 12 val_loss = 4.161652 train_loss = 3.0834975\n",
      "[[6.30081  ]\n",
      " [5.8237376]\n",
      " [5.920193 ]\n",
      " [5.868112 ]\n",
      " [5.8343797]\n",
      " [6.3011165]\n",
      " [5.8388524]\n",
      " [5.8722405]\n",
      " [5.8701   ]\n",
      " [5.8509083]]\n",
      "Epoch = 13 val_loss = 4.130951 train_loss = 3.055846\n",
      "[[5.8899746]\n",
      " [5.950701 ]\n",
      " [5.951007 ]\n",
      " [5.993256 ]\n",
      " [5.9507027]\n",
      " [5.8899746]\n",
      " [5.950701 ]\n",
      " [5.950701 ]\n",
      " [5.950701 ]\n",
      " [5.950701 ]]\n",
      "Epoch = 14 val_loss = 4.136366 train_loss = 3.1127043\n",
      "[[5.9158063]\n",
      " [5.8933854]\n",
      " [5.765001 ]\n",
      " [5.8952856]\n",
      " [5.8933854]\n",
      " [5.920149 ]\n",
      " [5.893385 ]\n",
      " [5.8249464]\n",
      " [5.8249464]\n",
      " [5.824947 ]]\n",
      "Epoch = 15 val_loss = 4.1324697 train_loss = 3.0884018\n",
      "[[5.8935056]\n",
      " [5.9172597]\n",
      " [5.8972974]\n",
      " [5.901143 ]\n",
      " [5.9172597]\n",
      " [5.8935075]\n",
      " [5.9172597]\n",
      " [5.8689985]\n",
      " [5.8689985]\n",
      " [5.8690066]]\n",
      "Epoch = 16 val_loss = 4.1331067 train_loss = 3.0929673\n",
      "[[5.884821 ]\n",
      " [5.8922873]\n",
      " [5.8826256]\n",
      " [5.902658 ]\n",
      " [5.892287 ]\n",
      " [5.8848386]\n",
      " [5.892287 ]\n",
      " [5.8821   ]\n",
      " [5.8821   ]\n",
      " [5.8821006]]\n",
      "Epoch = 17 val_loss = 4.1413164 train_loss = 2.9917665\n",
      "[[6.013819 ]\n",
      " [6.0729775]\n",
      " [6.1749797]\n",
      " [6.0728297]\n",
      " [6.075519 ]\n",
      " [6.0138717]\n",
      " [6.077195 ]\n",
      " [6.069431 ]\n",
      " [6.0651164]\n",
      " [6.0769725]]\n",
      "Epoch = 18 val_loss = 4.132412 train_loss = 3.038724\n",
      "[[6.0433474]\n",
      " [5.9470034]\n",
      " [5.9933515]\n",
      " [5.947012 ]\n",
      " [5.9468813]\n",
      " [6.0451894]\n",
      " [5.956569 ]\n",
      " [5.9475393]\n",
      " [5.947341 ]\n",
      " [5.9475393]]\n",
      "Epoch = 19 val_loss = 4.1338816 train_loss = 3.095499\n",
      "[[5.8874583]\n",
      " [5.8596444]\n",
      " [5.889928 ]\n",
      " [5.8492265]\n",
      " [5.8596506]\n",
      " [5.86209  ]\n",
      " [5.9108505]\n",
      " [5.9108505]\n",
      " [5.9108505]\n",
      " [5.910851 ]]\n",
      "Epoch = 20 val_loss = 4.1594234 train_loss = 3.0046616\n",
      "[[5.933669 ]\n",
      " [6.2016582]\n",
      " [5.8571005]\n",
      " [6.2160835]\n",
      " [6.201658 ]\n",
      " [5.9542255]\n",
      " [6.0786395]\n",
      " [6.0786395]\n",
      " [6.07864  ]\n",
      " [6.0786395]]\n",
      "Epoch = 21 val_loss = 4.1290326 train_loss = 3.0694838\n",
      "[[5.9337077]\n",
      " [5.9047575]\n",
      " [5.9291577]\n",
      " [5.8990064]\n",
      " [5.9046993]\n",
      " [5.9337077]\n",
      " [5.9171352]\n",
      " [5.9291577]\n",
      " [5.9291577]\n",
      " [5.9295063]]\n",
      "Epoch = 22 val_loss = 4.1346364 train_loss = 3.0905383\n",
      "[[5.7695   ]\n",
      " [5.9761524]\n",
      " [5.9245734]\n",
      " [5.9160724]\n",
      " [5.952237 ]\n",
      " [5.712829 ]\n",
      " [5.9811044]\n",
      " [5.9245734]\n",
      " [5.9245734]\n",
      " [5.9245734]]\n",
      "Epoch = 23 val_loss = 4.135096 train_loss = 3.0473144\n",
      "[[5.7782507]\n",
      " [6.0077324]\n",
      " [6.023087 ]\n",
      " [5.9572954]\n",
      " [6.0077324]\n",
      " [5.77825  ]\n",
      " [6.1131673]\n",
      " [6.023087 ]\n",
      " [6.023087 ]\n",
      " [6.023087 ]]\n",
      "Epoch = 24 val_loss = 4.1464276 train_loss = 3.0395236\n",
      "[[6.120131 ]\n",
      " [5.84218  ]\n",
      " [6.1278977]\n",
      " [5.84218  ]\n",
      " [5.84218  ]\n",
      " [5.9886894]\n",
      " [5.8543615]\n",
      " [6.1278977]\n",
      " [6.1278977]\n",
      " [6.1278977]]\n",
      "Epoch = 25 val_loss = 4.133794 train_loss = 3.0583205\n",
      "[[5.821731 ]\n",
      " [5.9939537]\n",
      " [5.844473 ]\n",
      " [5.9939537]\n",
      " [5.9939537]\n",
      " [5.821731 ]\n",
      " [6.015977 ]\n",
      " [5.997899 ]\n",
      " [5.997899 ]\n",
      " [5.9896264]]\n",
      "Epoch = 26 val_loss = 4.1411505 train_loss = 3.0294662\n",
      "[[5.770299 ]\n",
      " [6.096463 ]\n",
      " [6.038586 ]\n",
      " [6.096463 ]\n",
      " [6.096463 ]\n",
      " [5.770299 ]\n",
      " [6.0717235]\n",
      " [6.0717235]\n",
      " [6.0717235]\n",
      " [6.0717235]]\n",
      "Epoch = 27 val_loss = 4.144032 train_loss = 3.053618\n",
      "[[5.953544 ]\n",
      " [6.1217504]\n",
      " [5.818979 ]\n",
      " [6.0923815]\n",
      " [6.11334  ]\n",
      " [5.962995 ]\n",
      " [5.934381 ]\n",
      " [5.876678 ]\n",
      " [5.876678 ]\n",
      " [5.876678 ]]\n",
      "Epoch = 28 val_loss = 4.1336293 train_loss = 3.1017714\n",
      "[[5.91739  ]\n",
      " [5.9076138]\n",
      " [5.843273 ]\n",
      " [5.9076138]\n",
      " [5.9076138]\n",
      " [5.9197044]\n",
      " [5.8432755]\n",
      " [5.843273 ]\n",
      " [5.843273 ]\n",
      " [5.8436313]]\n",
      "Epoch = 29 val_loss = 4.133701 train_loss = 3.053211\n",
      "[[5.977197 ]\n",
      " [6.0679865]\n",
      " [5.89166  ]\n",
      " [5.996041 ]\n",
      " [6.0679865]\n",
      " [5.9661393]\n",
      " [5.89166  ]\n",
      " [5.89166  ]\n",
      " [5.89166  ]\n",
      " [5.89166  ]]\n",
      "Epoch = 30 val_loss = 4.1529145 train_loss = 3.1808898\n",
      "[[5.842124 ]\n",
      " [5.7641087]\n",
      " [5.790637 ]\n",
      " [5.7938833]\n",
      " [5.753096 ]\n",
      " [5.844332 ]\n",
      " [5.7657647]\n",
      " [5.7657647]\n",
      " [5.7657647]\n",
      " [5.7657647]]\n",
      "Epoch = 31 val_loss = 4.1285987 train_loss = 3.0599623\n",
      "[[5.9142585]\n",
      " [5.92494  ]\n",
      " [5.9517508]\n",
      " [5.993709 ]\n",
      " [5.9130836]\n",
      " [5.9180903]\n",
      " [5.935716 ]\n",
      " [5.935716 ]\n",
      " [5.935716 ]\n",
      " [5.935716 ]]\n",
      "Epoch = 32 val_loss = 4.1298723 train_loss = 3.0930982\n",
      "[[5.940989 ]\n",
      " [5.9202447]\n",
      " [5.916208 ]\n",
      " [5.7599936]\n",
      " [5.9202447]\n",
      " [5.8952503]\n",
      " [5.888147 ]\n",
      " [5.8881445]\n",
      " [5.8881445]\n",
      " [5.8881445]]\n",
      "Epoch = 33 val_loss = 4.133306 train_loss = 3.0987453\n",
      "[[5.928804 ]\n",
      " [5.8889837]\n",
      " [5.863982 ]\n",
      " [5.832025 ]\n",
      " [5.8889837]\n",
      " [5.913837 ]\n",
      " [5.8889837]\n",
      " [5.91229  ]\n",
      " [5.847639 ]\n",
      " [5.8476396]]\n",
      "Epoch = 34 val_loss = 4.147017 train_loss = 3.0346453\n",
      "[[6.1121407]\n",
      " [5.957714 ]\n",
      " [6.0166187]\n",
      " [6.0463376]\n",
      " [6.0060368]\n",
      " [6.1121407]\n",
      " [5.9071646]\n",
      " [5.9071646]\n",
      " [5.9071646]\n",
      " [5.9071646]]\n",
      "Epoch = 35 val_loss = 4.155738 train_loss = 3.1170547\n",
      "[[6.210012 ]\n",
      " [5.8027287]\n",
      " [5.818511 ]\n",
      " [5.8413997]\n",
      " [5.8027287]\n",
      " [6.210017 ]\n",
      " [5.8038855]\n",
      " [5.8038855]\n",
      " [5.8027287]\n",
      " [5.8038855]]\n",
      "Epoch = 36 val_loss = 4.18603 train_loss = 2.9797485\n",
      "[[5.9167185]\n",
      " [6.256057 ]\n",
      " [6.166468 ]\n",
      " [6.3531623]\n",
      " [6.256057 ]\n",
      " [5.9167185]\n",
      " [6.257804 ]\n",
      " [6.2577715]\n",
      " [6.2577715]\n",
      " [6.2781773]]\n",
      "Epoch = 37 val_loss = 4.1522737 train_loss = 2.9897387\n",
      "[[5.9910994]\n",
      " [6.105272 ]\n",
      " [6.187326 ]\n",
      " [6.105272 ]\n",
      " [6.105272 ]\n",
      " [5.9910994]\n",
      " [6.1042786]\n",
      " [6.070772 ]\n",
      " [6.070772 ]\n",
      " [6.070772 ]]\n",
      "Epoch = 38 val_loss = 4.171262 train_loss = 3.0212874\n",
      "[[6.215643 ]\n",
      " [5.992792 ]\n",
      " [5.940221 ]\n",
      " [6.247575 ]\n",
      " [5.992792 ]\n",
      " [6.215643 ]\n",
      " [5.9927554]\n",
      " [5.909799 ]\n",
      " [5.909799 ]\n",
      " [5.9390163]]\n",
      "Epoch = 39 val_loss = 4.1403265 train_loss = 3.0142622\n",
      "[[5.903572 ]\n",
      " [6.0661106]\n",
      " [6.0362015]\n",
      " [6.0661097]\n",
      " [6.0661106]\n",
      " [5.903572 ]\n",
      " [6.0661106]\n",
      " [6.063885 ]\n",
      " [6.027232 ]\n",
      " [6.0331984]]\n",
      "Epoch = 40 val_loss = 4.161927 train_loss = 3.0185423\n",
      "[[5.73791  ]\n",
      " [6.1529837]\n",
      " [6.1188817]\n",
      " [6.13262  ]\n",
      " [6.1529837]\n",
      " [5.73791  ]\n",
      " [6.12951  ]\n",
      " [6.2201986]\n",
      " [6.2201986]\n",
      " [6.12951  ]]\n",
      "Epoch = 41 val_loss = 4.1552176 train_loss = 2.9973927\n",
      "[[6.1391783]\n",
      " [6.0410585]\n",
      " [5.985603 ]\n",
      " [6.052927 ]\n",
      " [6.0410585]\n",
      " [6.1391783]\n",
      " [6.0410585]\n",
      " [6.052927 ]\n",
      " [6.0410585]\n",
      " [6.0410585]]\n",
      "Epoch = 42 val_loss = 4.1280923 train_loss = 3.0621908\n",
      "[[5.9422083]\n",
      " [5.9265523]\n",
      " [5.9393525]\n",
      " [5.926198 ]\n",
      " [5.9265523]\n",
      " [5.940431 ]\n",
      " [5.926582 ]\n",
      " [5.930721 ]\n",
      " [5.9302173]\n",
      " [5.928585 ]]\n",
      "Epoch = 43 val_loss = 4.1284914 train_loss = 3.057643\n",
      "[[5.9655757]\n",
      " [5.9110603]\n",
      " [5.9306345]\n",
      " [5.92083  ]\n",
      " [5.9110603]\n",
      " [5.965574 ]\n",
      " [5.911151 ]\n",
      " [5.9366727]\n",
      " [5.960001 ]\n",
      " [5.984705 ]]\n",
      "Epoch = 44 val_loss = 4.1280994 train_loss = 3.064307\n",
      "[[5.9325547]\n",
      " [5.9339037]\n",
      " [5.944772 ]\n",
      " [5.9297523]\n",
      " [5.9339037]\n",
      " [5.9253817]\n",
      " [5.9339237]\n",
      " [5.918126 ]\n",
      " [5.909594 ]\n",
      " [5.9241667]]\n",
      "Epoch = 45 val_loss = 4.12899 train_loss = 3.0723574\n",
      "[[5.919281 ]\n",
      " [5.909828 ]\n",
      " [5.9244213]\n",
      " [5.913708 ]\n",
      " [5.909828 ]\n",
      " [5.9404154]\n",
      " [5.9129424]\n",
      " [5.9198494]\n",
      " [5.9114714]\n",
      " [5.9050937]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 46 val_loss = 4.1340375 train_loss = 3.1255758\n",
      "[[5.8180704]\n",
      " [5.891139 ]\n",
      " [5.8711295]\n",
      " [5.911519 ]\n",
      " [5.891139 ]\n",
      " [5.8180704]\n",
      " [5.960487 ]\n",
      " [5.8620777]\n",
      " [5.7648706]\n",
      " [5.7278547]]\n",
      "Epoch = 47 val_loss = 4.1293983 train_loss = 3.051336\n",
      "[[6.006445 ]\n",
      " [5.995334 ]\n",
      " [5.9032474]\n",
      " [5.964033 ]\n",
      " [5.995334 ]\n",
      " [6.006441 ]\n",
      " [5.9754496]\n",
      " [5.874817 ]\n",
      " [5.931191 ]\n",
      " [5.874817 ]]\n",
      "Epoch = 48 val_loss = 4.131523 train_loss = 3.073055\n",
      "[[6.003201 ]\n",
      " [5.912868 ]\n",
      " [5.8766794]\n",
      " [5.921221 ]\n",
      " [5.9129024]\n",
      " [6.003201 ]\n",
      " [5.831009 ]\n",
      " [5.9186893]\n",
      " [5.8831835]\n",
      " [5.929151 ]]\n",
      "Epoch = 49 val_loss = 4.1469116 train_loss = 3.0766354\n",
      "[[5.8565636]\n",
      " [6.04903  ]\n",
      " [5.7354593]\n",
      " [6.07049  ]\n",
      " [6.0438056]\n",
      " [5.8565636]\n",
      " [6.048743 ]\n",
      " [5.7354593]\n",
      " [6.0126343]\n",
      " [5.923004 ]]\n",
      "Epoch = 50 val_loss = 4.1333723 train_loss = 3.0231059\n",
      "[[5.9253607]\n",
      " [6.0706053]\n",
      " [5.958553 ]\n",
      " [6.047115 ]\n",
      " [6.0706053]\n",
      " [5.942705 ]\n",
      " [6.0041676]\n",
      " [6.0163307]\n",
      " [6.01635  ]\n",
      " [5.973153 ]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i in range(n_batch):\n",
    "        if i == n_batch - 1:\n",
    "            batch_x = train_X[batch_size*i:]\n",
    "            batch_y = train_Y[batch_size*i:]\n",
    "        else:\n",
    "            batch_x = train_X[batch_size*i: batch_size*(i+1)]\n",
    "            batch_y = train_Y[batch_size*i: batch_size*(i+1)]\n",
    "        \n",
    "        feed_dict = {\n",
    "            X: batch_x,\n",
    "            Y: batch_y\n",
    "        }\n",
    "        sess.run(train_step, feed_dict = feed_dict)\n",
    "    \n",
    "    feed_dict = {\n",
    "        X: train_X[0:10],\n",
    "        Y: train_Y[0:10]\n",
    "    }\n",
    "    train_loss, pre = sess.run([loss, out], feed_dict = feed_dict)\n",
    "    \n",
    "    feed_dict = {\n",
    "        X: val_X,\n",
    "        Y: val_Y\n",
    "    }\n",
    "    test_loss = sess.run(loss, feed_dict = feed_dict)\n",
    "    print('Epoch =', (epoch+1), 'val_loss =', test_loss, 'train_loss =',train_loss )\n",
    "    print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Final Model\n",
    "\n",
    "train_X1 = t_data.drop('fof2', axis = 1)\n",
    "train_Y1 = t_data['fof2']\n",
    "\n",
    "n_batch = int(train_X1.shape[0]/batch_size) + 1\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(n_batch):\n",
    "        if i == n_batch - 1:\n",
    "            batch_x = train_X1[batch_size*i:]\n",
    "            batch_y = train_Y1[batch_size*i:]\n",
    "        else:\n",
    "            batch_x = train_X1[batch_size*i: batch_size*(i+1)]\n",
    "            batch_y = train_Y1[batch_size*i: batch_size*(i+1)]\n",
    "        \n",
    "        feed_dict = {\n",
    "            X: batch_x,\n",
    "            Y: batch_y\n",
    "        }\n",
    "        sess.run(train_step, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict\n",
    "\n",
    "test_data1 = pd.DataFrame(scale(test_data.drop(['Time', 'fof2'], axis = 1)))\n",
    "\n",
    "feed_dict = {X: test_data1}\n",
    "prediction = sess.run(out, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.7846093, 4.7846093)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.min(), prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
